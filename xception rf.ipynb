{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import * \n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "# To initialize neural network\n",
    "from keras.layers import Convolution2D\n",
    "# Images are two dimensional, concolution step\n",
    "from keras.layers import MaxPooling2D\n",
    "# Pooling step\n",
    "from keras.layers import Flatten\n",
    "# Convert pools feature map into this large feature vector\n",
    "from keras.layers import Dense\n",
    "#To add fully connected layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.xception import Xception\n",
    "#from keras.applications.InceptionResNetV2 import InceptionResNetV2\n",
    "from keras import applications\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "# To initialize neural network\n",
    "from keras.layers import Convolution2D\n",
    "# Images are two dimensional, concolution step\n",
    "from keras.layers import MaxPooling2D\n",
    "# Pooling step\n",
    "from keras.layers import Flatten\n",
    "# Convert pools feature map into this large feature vector\n",
    "from keras.layers import Dense\n",
    "#To add fully connected layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications import resnet50\n",
    "from keras.models import Model\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 224\n",
    "TRAIN_DIR= 'imagesdata/train/'\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for img_label in (os.listdir(TRAIN_DIR)):\n",
    "    img_dir=os.path.join(TRAIN_DIR,img_label)\n",
    "    for img_name in (os.listdir(img_dir)):\n",
    "        img_path=os.path.join(img_dir,img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(img_label)\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "SIZE = 224\n",
    "TEST_DIR= 'imagesdata/test/'\n",
    "test_images = []\n",
    "test_labels = [] \n",
    "for img_label in (os.listdir(TEST_DIR)):\n",
    "    img_dir=os.path.join(TEST_DIR,img_label)\n",
    "    for img_name in (os.listdir(img_dir)):\n",
    "        img_path=os.path.join(img_dir,img_name)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (SIZE, SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        test_images.append(img)\n",
    "        test_labels.append(img_label)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "#########################################################\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(test_labels)\n",
    "test_labels_encoded = le.transform(test_labels)\n",
    "le.fit(train_labels)\n",
    "train_labels_encoded = le.transform(train_labels)\n",
    "\n",
    "#Split data into test and train datasets (already split but assigning to meaningful convention)\n",
    "\n",
    "x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded\n",
    "\n",
    "###################################################################\n",
    "# Normalize pixel values to between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "#One hot encode y values for neural network. \n",
    "from keras.utils import to_categorical\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test_one_hot[150:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE_SIZE = 224\n",
    "pretrained_model =applications.Xception(input_shape=(224,224, 3), include_top=False)\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    pretrained_model,\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(learning_rate=0.01, momentum=0.1, activation='relu', init_weights='uniform', optimizer='Adam'):   \n",
    "    pretrained_model =applications.Xception(input_shape=(224,224, 3), include_top=False)\n",
    "    pretrained_model.trainable = False\n",
    "\n",
    "    model = Sequential([\n",
    "    pretrained_model,\n",
    "    Flatten(),\n",
    "    Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,      \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "123/123 [==============================] - 44s 355ms/step - loss: 3.0422 - accuracy: 0.5772\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 41s 333ms/step - loss: 2.3570 - accuracy: 0.5691\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 39s 319ms/step - loss: 1.1648 - accuracy: 0.7724\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 39s 320ms/step - loss: 0.3634 - accuracy: 0.9431\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 42s 340ms/step - loss: 0.2909 - accuracy: 0.9187\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 39s 320ms/step - loss: 0.0381 - accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 40s 322ms/step - loss: 0.0700 - accuracy: 0.9837\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 40s 323ms/step - loss: 0.0083 - accuracy: 0.9919\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 40s 324ms/step - loss: 1.6665e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 40s 325ms/step - loss: 1.9277e-04 - accuracy: 1.0000\n",
      "62/62 [==============================] - 24s 382ms/step\n",
      "Epoch 1/10\n",
      "123/123 [==============================] - 43s 351ms/step - loss: 3.3525 - accuracy: 0.6016\n",
      "Epoch 2/10\n",
      "123/123 [==============================] - 39s 319ms/step - loss: 1.4402 - accuracy: 0.6911\n",
      "Epoch 3/10\n",
      "123/123 [==============================] - 40s 322ms/step - loss: 0.6605 - accuracy: 0.8537\n",
      "Epoch 4/10\n",
      "123/123 [==============================] - 42s 338ms/step - loss: 0.1433 - accuracy: 0.9512\n",
      "Epoch 5/10\n",
      "123/123 [==============================] - 39s 314ms/step - loss: 0.1611 - accuracy: 0.9350\n",
      "Epoch 6/10\n",
      "123/123 [==============================] - 41s 334ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "123/123 [==============================] - 39s 318ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "123/123 [==============================] - 39s 318ms/step - loss: 0.0211 - accuracy: 0.9919\n",
      "Epoch 9/10\n",
      "123/123 [==============================] - 40s 326ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "123/123 [==============================] - 39s 317ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "62/62 [==============================] - 22s 351ms/step\n",
      "Epoch 1/10\n",
      "124/124 [==============================] - 42s 343ms/step - loss: 0.7682 - accuracy: 0.7016\n",
      "Epoch 2/10\n",
      "124/124 [==============================] - 40s 320ms/step - loss: 0.3189 - accuracy: 0.8790\n",
      "Epoch 3/10\n",
      "124/124 [==============================] - 40s 324ms/step - loss: 0.0961 - accuracy: 0.9758\n",
      "Epoch 4/10\n",
      "124/124 [==============================] - 42s 337ms/step - loss: 0.0118 - accuracy: 0.9919\n",
      "Epoch 5/10\n",
      "124/124 [==============================] - 39s 318ms/step - loss: 0.0343 - accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "124/124 [==============================] - 39s 318ms/step - loss: 5.2395e-04 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "124/124 [==============================] - 40s 322ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "124/124 [==============================] - 40s 321ms/step - loss: 4.8046e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "124/124 [==============================] - 40s 319ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "124/124 [==============================] - 40s 322ms/step - loss: 6.4036e-05 - accuracy: 1.0000\n",
      "61/61 [==============================] - 22s 357ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "185/185 [==============================] - 62s 334ms/step - loss: 4.1779 - accuracy: 0.4973\n",
      "Epoch 2/10\n",
      "185/185 [==============================] - 59s 320ms/step - loss: 1.8327 - accuracy: 0.6919\n",
      "Epoch 3/10\n",
      "185/185 [==============================] - 59s 317ms/step - loss: 0.5884 - accuracy: 0.8432\n",
      "Epoch 4/10\n",
      "185/185 [==============================] - 60s 322ms/step - loss: 0.2809 - accuracy: 0.9459\n",
      "Epoch 5/10\n",
      "185/185 [==============================] - 60s 325ms/step - loss: 0.1979 - accuracy: 0.9676\n",
      "Epoch 6/10\n",
      "185/185 [==============================] - 59s 320ms/step - loss: 0.0657 - accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "185/185 [==============================] - 59s 318ms/step - loss: 0.0899 - accuracy: 0.9730\n",
      "Epoch 8/10\n",
      "185/185 [==============================] - 60s 322ms/step - loss: 0.1424 - accuracy: 0.9676\n",
      "Epoch 9/10\n",
      "185/185 [==============================] - 59s 317ms/step - loss: 0.0162 - accuracy: 0.9946\n",
      "Epoch 10/10\n",
      "185/185 [==============================] - 59s 317ms/step - loss: 0.0817 - accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "#Take a subset of train for grid search. Let us take 10% for now\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_grid, x_not_use, y_grid, y_not_use = train_test_split(x_train, y_train, test_size=0.9, random_state=42)\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = KerasClassifier(build_fn=define_model, \n",
    "                        epochs=epochs, \n",
    "                        batch_size = batch_size, \n",
    "                        verbose=1)\n",
    "\n",
    "learning_rate = [0.001]\n",
    "momentum = [0.9]\n",
    "\n",
    "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
    "# -1 refers to using all available CPUs\n",
    "#Cross validation, cv=3\n",
    "\n",
    "init_weights = ['uniform']\n",
    "#Also try lecun_uniform, he_normal, glorot_normal, etc. \n",
    "optimizer = ['Adam']\n",
    "\n",
    "param_grid = dict( init_weights=init_weights, optimizer=optimizer,learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
    "# -1 refers to using all available CPUs\n",
    "#Cross validation, cv=3\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=None, cv=3) 87.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    "\n",
    "grid_result = grid.fit(x_grid, y_grid)\n",
    "\n",
    "# summarize results+\n",
    "#print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "learning_rate is not a legal parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 503, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 115, in set_params\n    self.check_params(params)\n  File \"C:\\Users\\banik\\Anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\", line 91, in check_params\n    '{} is not a legal parameter'.format(params_name))\nValueError: learning_rate is not a legal parameter\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-d3eef03884e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# summarize results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    665\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 667\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    433\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: learning_rate is not a legal parameter"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "model = KerasClassifier(build_fn=define_model, \n",
    "                        epochs=epochs, \n",
    "                        batch_size = batch_size, \n",
    "                        verbose=1)\n",
    "\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "momentum = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "#n_jobs=16 uses 16 CPUs. Try not to do -1 on your system as it may hang!!!\n",
    "# -1 refers to using all available CPUs\n",
    "#Cross validation, cv=3\n",
    "param_grid = dict(learning_rate=learning_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=16, cv=3)\n",
    "\n",
    "grid_result = grid.fit(x_grid, y_grid)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.502703 using {'init_weights': 'uniform', 'learning_rate': 0.001, 'momentum': 0.9, 'optimizer': 'Adam'}\n",
      "Mean = 0.502703 (std=0.103668) with: {'init_weights': 'uniform', 'learning_rate': 0.001, 'momentum': 0.9, 'optimizer': 'Adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"Mean = %f (std=%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
